{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B5GLwNymIuV2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "27316d67-5031-433f-f7a4-2d144947a830"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2822975963.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# plt.style.use('dark_background')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_mats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecile_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnalyseMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_print_mats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxclib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageOps\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xc'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Add, Dense, Dropout, Layer, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError\n",
        "# from tensorflow_addons.metrics import RSquare\n",
        "# from wandb.keras import WandbCallback\n",
        "\n",
        "import math\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# import tensorflow_probability as tfp\n",
        "# import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.style.use('dark_background')\n",
        "\n",
        "from xc.tools.analysis import print_mats, decile_plot, AnalyseMatrix, load_overlap, _print_mats\n",
        "from xclib.data import data_utils as du\n",
        "import PIL.ImageOps as ImageOps\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "from io import BytesIO\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import pickle as p\n",
        "\n",
        "from textwrap import wrap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# work_dir=f\"{os.environ['HOME']}/scratch/XC\"\n",
        "# dset=\"G-LF-WikiTitles-1M\"\n",
        "# data_dir=f\"{os.environ['HOME']}/data/{dset}\"\n",
        "# score_mat_dir=f\"{work_dir}/score_mats/{dset}\"\n",
        "# os.makedirs(score_mat_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "32vTq0NdRl3O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_topk=5\n",
        "\n",
        "raw_images=f\"{data_dir}/images\"\n",
        "k = 5\n",
        "A, B = 0.6, 2.6\n",
        "\n",
        "tst_map = list(map(lambda x: x.strip(), open(f\"{data_dir}/raw_data/test.raw.txt\", \"r\").readlines()))\n",
        "lbl_map = list(map(lambda x: x.strip(), open(f\"{data_dir}/raw_data/label.raw.txt\", \"r\").readlines()))\n",
        "\n",
        "trn_y = du.read_sparse_file(f\"{data_dir}/trn_X_Y.txt\")\n",
        "tst_y = du.read_sparse_file(f\"{data_dir}/tst_X_Y.txt\")\n",
        "\n",
        "trn_imgs, lbl_imgs = None, None,\n",
        "if os.path.exists(f\"{data_dir}/images/label.img.bin.npz\"):\n",
        "    lbl_imgs = sp.load_npz(f\"{data_dir}/images/label.img.bin.npz\")\n",
        "    trn_imgs = sp.load_npz(f\"{data_dir}/images/train.img.bin.npz\")\n",
        "    tst_imgs = sp.load_npz(f\"{data_dir}/images/test.img.bin.npz\")\n",
        "    imgs = open(f\"{data_dir}/images/img.bin\", \"r\")\n",
        "filter_items = load_overlap(f\"{data_dir}/filter_labels_test.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9q7A6glrRlzs",
        "outputId": "64de6096-eafb-41ff-cad4-3a31384536dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3865500446.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_topk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{data_dir}/images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_mats = {\n",
        "    \"ELIAS\": f\"{score_mat_dir}/ELIAS/score.npz\",\n",
        "    \"NGAME\": f\"{score_mat_dir}/NGAME/score.npz\"\n",
        "}\n",
        "score_mats = AnalyseMatrix(score_mats, _topk, filter_items)\n",
        "sorted_mats = [\"ELIAS\", \"NGAME\"]\n",
        "strict_mats = [-1, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "x17-cZNWRlxr",
        "outputId": "00e50b89-d1df-4bba-ff6d-3ff995fbf2b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'score_mat_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-1002466341.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m score_mats = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m\"ELIAS\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{score_mat_dir}/ELIAS/score.npz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"NGAME\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{score_mat_dir}/NGAME/score.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0mscore_mats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnalyseMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_mats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_topk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'score_mat_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xclib.data import data_utils\n",
        "\n",
        "# Read file with features and labels (old format from XMLRepo)\n",
        "features, tabels, num_samples, num_features, num_labels = data_utils.read_data('train.txt')\n",
        "\n",
        "# Read sparse file (see docstring for more)\n",
        "# header can be set to false (if required)\n",
        "labels = data_utils.read_sparse_file('trn_X_Xf.txt', header=True)\n",
        "\n",
        "# Write sparse file (with header)\n",
        "data_utils.write_sparse_file(labels, \"labels.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "l4ZMN_sWSCS1",
        "outputId": "89c53b23-5e3f-462d-cc7a-b7c9f94b6937"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xclib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-1004787140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxclib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Read file with features and labels (old format from XMLRepo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xclib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation\n",
        "Ensure that you have:\n",
        "\n",
        "amazon670k.train.txt – training data in LIBSVM format\n",
        "\n",
        "amazon670k.test.txt – test data in LIBSVM format"
      ],
      "metadata": {
        "id": "qDlZStsPQ7gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the XML tools repo\n",
        "!git clone https://github.com/xmc-aalto/xmltools.git\n",
        "%cd xmltools\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Convert from XML to LIBSVM (run only once)\n",
        "!python -m xmltools.datasets.amazon_to_libsvm --dataset-path /path/to/downloaded/amazon/ --output-folder /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lVkJcKMLEbs",
        "outputId": "1f649a03-b942-4b7e-e45d-37fcc70fd293"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'xmltools'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'xmltools'\n",
            "/content\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m/usr/bin/python3: Error while finding module specification for 'xmltools.datasets.amazon_to_libsvm' (ModuleNotFoundError: No module named 'xmltools')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/dismecpp/build/bin/train \\\n",
        "  /content/amazon670k.train.txt \\\n",
        "  amazon670k.model \\\n",
        "  --max-nr-labels 500000 \\\n",
        "  --normalize-instances \\\n",
        "  --threshold=0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "JMBN0XrrQmaV",
        "outputId": "4fdf51ac-9c65-4111-e38d-1cd4eaa1cb92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-13-883635568.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-13-883635568.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content/dismecpp/build/bin/train(/content/amazon670k.train.txt, amazon670k.model, --max-nr-labels, 500000, --normalize-instances, --threshold=0.01)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/dismecpp/build/bin/predict \\\n",
        "  /content/amazon670k.test.txt \\\n",
        "  amazon670k.model \\\n",
        "  amazon670k_pred.txt \\\n",
        "  --augment-for-bias \\\n",
        "  --normalize-instances \\\n",
        "  --topk=5"
      ],
      "metadata": {
        "id": "kux_XA2oQmcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def parse_true_labels(file_path):\n",
        "    labels = []\n",
        "    with open(file_path) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith('#'):\n",
        "                continue\n",
        "            label_str = line.split(' ')[0]  # extract '1,2,3'\n",
        "            label_ids = list(map(int, label_str.split(',')))\n",
        "            labels.append(set(label_ids))\n",
        "    return labels\n",
        "\n",
        "def parse_pred_scores(file_path, top_k=5):\n",
        "    predictions = []\n",
        "    with open(file_path) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                predictions.append([])\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            sorted_pairs = sorted([tuple(map(float, p.split(':')[::-1])) for p in parts], reverse=True)\n",
        "            top_preds = [int(idx) for score, idx in sorted_pairs[:top_k]]\n",
        "            predictions.append(top_preds)\n",
        "    return predictions\n",
        "\n",
        "def precision_at_k(true_labels, pred_labels, k):\n",
        "    precisions = []\n",
        "    for true, pred in zip(true_labels, pred_labels):\n",
        "        pred_k = pred[:k]\n",
        "        if not pred_k:\n",
        "            precisions.append(0.0)\n",
        "        else:\n",
        "            precisions.append(len(set(pred_k) & true) / k)\n",
        "    return np.mean(precisions)\n",
        "\n",
        "def ndcg_at_k(true_labels, pred_labels, k):\n",
        "    ndcgs = []\n",
        "    for true, pred in zip(true_labels, pred_labels):\n",
        "        dcg = 0.0\n",
        "        for i, p in enumerate(pred[:k]):\n",
        "            if p in true:\n",
        "                dcg += 1.0 / np.log2(i + 2)\n",
        "        ideal_dcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(true), k)))\n",
        "        ndcgs.append(dcg / ideal_dcg if ideal_dcg > 0 else 0.0)\n",
        "    return np.mean(ndcgs)\n",
        "\n",
        "def evaluate_all(true_file, pred_file, k_list=[1, 3, 5]):\n",
        "    true_labels = parse_true_labels(true_file)\n",
        "    results = {}\n",
        "    for k in k_list:\n",
        "        pred_labels = parse_pred_scores(pred_file, top_k=k)\n",
        "        results[f\"precision_at_{k}\"] = precision_at_k(true_labels, pred_labels, k)\n",
        "        results[f\"ndcg_at_{k}\"] = ndcg_at_k(true_labels, pred_labels, k)\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "true_file = \"/content/amazon670k.test.txt\"\n",
        "pred_file = \"/content/amazon670k_pred.txt\"\n",
        "k_list = [1, 3, 5]\n",
        "\n",
        "results = evaluate_all(true_file, pred_file, k_list)\n",
        "\n",
        "with open(\"amazon670k_metrics.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(json.dumps(results, indent=4))\n"
      ],
      "metadata": {
        "id": "OLpLyBuiQmeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83FmoYrJSYVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}